{"pages":[{"title":"","text":"唐艺昕 李沁 李一桐 gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"个人简介 分享很喜欢的老罗的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。“ 善恶终有报,天道好轮回。不信抬头看,苍天饶过谁。无论何时何地，我们都要保持一颗积极乐观、善良感恩的心。但行好事莫问前程，永远年轻，永远热内盈眶，永远保持正能量。💪💪💪💪💪💪冲鸭！！！！ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：计算机科学与技术专业从事JAVA后端开发码畜一枚坚信代码改变世界 博客信息 网站采用的Icarus主题 追求尽可能的简洁，清晰，易用。 在Icarus主题之上进行了部分修改。 更新日志：–2020.01.18：icarus3.0适配–2019.11.17：增加深色主题开关–2019.10.30：去图，精简卡片–2019.10.22：改版部分显示，优化速度–2019.10.16：文章列表加上评论数显示–2019.10.13：改版评论–2019.09.25：图片、资源接入CDN免费jsDelivr、文章加入置顶–2019.09.19：开源博客代码–2019.09.19：修改布局，拉伸布局，更宽的展示–2019.09.18：修改友链ui为一行三个，并适配移动端，暗黑模式文章增加评论链接，增加留言链接–2019.09.14：增加精简next主题–2019.09.14：利用中秋节放假，重做了首页的热门推荐、加个widget最新评论框、归档页加入文章贡献概览面板 本站推荐索引 博客主题相关 github Issue 作为博客微型数据库的应用 github page网站cdn优化加速 博客源码分享 博客换肤的一种实现方式思路 博客中gitalk最新评论的获取 博客图片上传picgo工具github图传使用 安装、部分配置icarus主题中文版 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享 计划2020计划 2019.12.31 2020-GOALS 跑两三场马拉松 2019计划 2018.12.31/21:59:00-&gt;更新于2019.12.31 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…）-&gt; 95% 额外： 追了很多剧 总结： 有优点有缺点，没坚持下来的还是太多，追了太多剧。以后多学习，多思考！ 时间轴记录","link":"/about/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://removeif.github.io/images/avatar.jpg 网站名称：辣椒の酱 网站地址：https://removeif.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"音乐歌单收藏","text":"--- 温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「12次查看」 var gitalk = new Gitalk({ clientID: 'Iv1.07b3daf43a7c754c', clientSecret: '7cde7de258b5783b64611061f585eb02402b4ee7', id: '62027', repo: 's-s-nian', owner: 'Sun-JunYu', admin: \"Sun-JunYu\", createIssueManually: true, distractionFreeMode: false }) gitalk.render('comment-container1')","link":"/self-talking/index.html"}],"posts":[{"title":"美好的一天","text":"嗨，请准确无误地输入密码查看哟（密码：123456）！ dab93704b6e6be5ad078b883d85d31c9f9f9243615a94157c32a07524a879e2422432442f3e670df3935808b12c44c7594593d2b2fda9be0fd9502a99446c2dea117ac952339007d108b0389f02d8809d284d396b501e59a2e7aec59eaf151589651d8c6f1578f627c8b6fc61f8063ea7097709f63848e49d2d518c34937efcdde5b485f1c4377b8d022f82739a08c4e631c4d515ab45ec1284623726cd8219148471f09451ad79e73dec9717c07c72e377b12d2dcaa1f43a5fcd8f02901dc9f894250a4100fda75e762f6d0d395f08c5cea9b0b108343aa2fe8bfe9a5c873e6bb60ea0371399db5fd3541279fa8036d6e5a14f6c34ca69d859c9430adf9e182b8915381bddc36dd1948409d232caf92f249dd2b4be495acb7ff279c1a8da51a16497f9147154688e26b429a4cdb7c94063d35c69277e14320316ea66b1edada9904e18a20df19f3095cfd5992939d358da39237160a3d89d59fe4eaf1ed010f180acc23a3c21c6c3655edcd91293d88e7f495e1e77645d051df8c2edd378764f85a77e4d118e1157602e8187e327075a6e2b91d914e79492d68882a286119d91e960d4bf44e7d2d37f96a094000117bf5f2442d6b056282c72a94ece3bebb2abacb59c64b581dc875d2be54358e56890979169c0d92e1ee141e25e877a748fd1b7061246fcebd650261b85b78bd4e813b3875208998cf253c333343abca51184625d8db1e2dd1aec2f85cccebb1d5e29be8376c56dd33ba5c5060f19065860426bb2e7e52659db810c39f43063365871d3562202576aaaa0115a3959498e8879d1abb72fb284014ad56af26a312c87b67e1d7495be4a435b7cf66e83501da0ec3e0892c1879d707eecaa030f6900b73352cf1129d557c23a088e1145dd7210446ed949fcc36014aec144c78b3559c7cdb38ae25a199ef289862165e1ac03c3650e00b85e995c04de48c5ca3c6783d5fb64e12cb1346040a1a249380f3cefce9c0bc4fb5c318b344b02b74cbff5b6cacc46e041e424eff4dd90d2d474a3817aec96174e4934ea212c8fb0bba7e228b5687f0f9feda9f6c782fcfcc3e1c0b88d47fe40b825a90d13c6dc7e7153c384d802702c3b2f2e48c1e487150033fa88ef5b4cced857632ee0989b31eaadca0db339f0e936c51bc045cb20f20ac9357fc1e14a86025ec1e10d08f18177f2c4198fecb3a23ff2de7802b975a23a19bde9a58d3577264ccbe4a5e58555d34a63ce30430da0ab73e716a8179b5101d876176757bb61948664312fcf656eaf278e6f00facd897f02e9234929876a1e8682e0f9fba4fd1116fa5aae7e06ea71ead3b34ca4fb82f9bcfa40581f235a543193c30e114a25791118d5d4b00fdc5c14d1cb12565971efb6698992920dc3e59d0af0e1cbb0687d9487da489c81ad9de8921690b96b2862b2c0d204d8e7320e908113087003fb75dfbdce71cb4f5d3cf63a8f33db2b6bee35af2ccd32c2b834f208ffd1bfe3f02dfa49d5dc39b7392e9adfb16d46960b3e7dd4e9424e679fd34c0a39d38f087f436464ccd6c552965f62082dcf730eff4bd74fd462810524a84b8cca0b451751ea6b0ca95cd4c837eb56a46925bc4f8fff025d12b43eca52427980aeca917cf3b0c725a607035f2798894a2b3eedfb9a267c4e94b1c95e5b779c057158e15fd92c4ed0168673df360a7a130d9d0610bce1b674248d5749d93edd001b296c086918ebd798e0b6f5c54e535e08cab476520fa99a5a476839b302e9eac672506d788cf23eddc2c985a8f537ade9f42dd389f2155d2863a248d1ce8f0304a5910782a59340e91d1df8c68bb5a707e3af4b472cbd78641946b2e15d78b64daabc91f9e65a45f25495eb89acd5c8f4adb3d32bc238c73da7115679859c8d4a772322db5288e351a3f953644ecc141e208cf6737fa204b5fedf0110922d9bb5433a8137e130d12a7055b9334d1243c08038270273a9507e507cda65064c42a348771aa093b722c05229c3e38bac87c6a73ff3fe1eb77c770831aa4b7c869ed37d0e952c5b2b139480d15eb5a832e3a3ec35d4957673109531b4da8b2b1305793deb57c212d0643ddf155a250f082391cf0f6e06d4a5d7207a2fd46b1fef21c8bd2e4c155b595b222f32176b8e79b043d201be8ef73a30f603e7d18b19eb2fd1b76689b5d272d60983edb8501c3fa832b1cf164c8926dd23bf47248cbf56edb30decf050e8d6732dc2ab7ba5bb14fd69d75ec9e1c0c4922b32bcc8b21bb905c3b1761f146c4537bd22f4989e3168514730a4bd666d8b15996e7586841fab26c5e52cc50ff1eeee6d4eade40789bc9b5d41a5851cd7569cd2160bc584b68b7792193591358c43b1fccbb79db7c9205618df2aca271874b1a95b490e2eea5103bdc4e0bb793b1b9189b128eaaea834be36f3eeef1f83bf635f28cb967a1348af36c62bc23e38c8efc3043ba56e8b96fbc97c3883a3e52f798b04c91cf9fff64547189c3c2db129a76318bddddcc84a28d4bcbb6d45b76e7ffdccf4d0373f54a66f64738fddf3d9acf21c2f9ec9499b389cbac294f7414b88c47a3d1f5f543cec278a674ac5ec0fb85b0acce5f89184d98eec8a5d4aff7fbd8ba44a7e48584cb9bad8203c7cef94d02a2e2c09ecc60b7202367460af63e1a7283f386220cc8ab3c372c22c489a64bd8621ecf050b313cc290667ffd389efb026be67c0c5ca0501e6776e3dc03c7e8bd0b618f110c22278871230c05c9d9d78242ea1fd03032f75a0dba7d385fd2e3bfe5e01968096ebc3a7a99a6fe3e5429ad285473e6277221239faeb3494a0c8412a295f20f4df413475139c0d8d65b7a077fd6aa388c36602bf633d4779f7e14348ab67951f6be10005c668cbd91cb8919a7adff2348af4828ba0be38aa51a22157602ee2501787712127127f3c83c779c4ce4a763893fa86e077a534eeb396a818f6fbb2e3c5d5f32dad46a39debe6412dacba8285f2e7e5630b90487b50b987aaac590cccd15147eb575ea20112d7a53ebebd3922046154036b3087c06b174bc5a1e81377f5ee7e665d78c221d6464a9384c02c2a1509c6b572dceef988dde9e577663d2d92a8a047610acea8ff2152b94352ab33a9d0cc0da9f42fa83736baea2790e1727ffef36d1397a108333e64bfa87cdf7e0c68607d9bf1776e9bc25eb090de89f7ddedd71ae806ddfdb45048dae7623dd9a18d460f9ba58595903e83289161e6fdbc4673b63d3285792d2fe858e1a67eec0e2efd682bce7e0773bd62734e25082a71644375b6f1ea3b9243316b1b27402d5971017ff452716ed58efda7f3956fb28258a0929067f9d38f4330c19daff3fa423ca989bac1fcba48574fd9dca023f36203913d20449e94ec85694f610d9c32fba8f447cdb7555c1dff5adfed16426cd5015650f66cc0b69898d182e6d8805391154dae78d15a4a7b396f0e1cb42b33a1b5d8cebe44fd38bfb8c268ee3928a0389023a184b9c5b48732851a537ca89af837115ffe3de2fcafa9ef586d44284330cd4a32589ca6aa131daa2d4128d7104b018612564d117243b3e0b32404b87a30cd5526e70b11f2cb978e44e9c44b6004693fcc877856ff29e73af4500502935a6d4e72ce9abf4b91545f988283475df37ece3d73e178f26fb39417fd99b1c10f75fbd663bd9279d6c738f5f5b7daf640e8a061078deb998f04f79eeb52e701f5a918ae8c958eea0f5e21c0578d8b8ebdcb4cac0c9a6a2eb85809de6efb30c0ea9909922f1ea824990ada5328614827e5b0cb430aa03969eb7cb0fb075bc0a9ceb5a86d83d8cf76ecbe7f76527b3950753baf7a8406ad0476e094bc9b962a072e480b474c60f721af6057278207030a9c3a05f6b70337396f2a9916bec002b2199dcc7e3bc462da7f89debb1bda63579d8f659d270bb7d7dff83b56e169d030cc81a9802ebadb15782e0babfeccb094e67f1fe9a65611fb4f7332dd7c8c7ad4e95257c0f8483a33b48bd7d254a7806f8ef26d7b49aaa27dffc3355956c20f266ffd99117992cf48835165880d84421fd5768878a77b1a05148790111a09ccc71b87def6ce994451c2f78ae4771b59ca01ee686934eebd3d7ef27bbc8b3c0b225dfbfa51025f3092fffb7412b6cef4300bbbe54eacdbd2eb700018850e03d11735e11e38dbaa94accbf1ea4f20c2579374a95e2fd89085aa3e57a6119528fba1cd970a6594ea3dfac71896a4cbbf895344a6ac01080f22d7208e299ad4befcede61e8eef7501cd1c820a31b0147dafe411facdd5a12ebadaac76225c9d7fbcb77bca1fe442c489569ff4eccdf1a862720cec94edcf9489cf34263ca7478a69de676def79cb2156ddc3ebb4d644ca628399253731ffee94d771f1d0a72819eda9306c5e2d20f8eea8ad5f72052bbbd5e35e1374b874115fb723f654dfb96023aa3e2612e0c255b08debb778ff347fdfca483b853a28b4a091ddff99fbfec19638455483b2cfd0ad8a2ca094296c9e9d717fea03602759f4e136f7eb17db1e7ae394e536feb6ba3cdd9d30b8b14ec4915cbcd2905c4e7ca40c2a151a8f28562fb0bec62b68760b8e8effb50167a6089a41295ea7b8d5bb3ab13adf1eb80e7e832760f79fa69417d040c2b91312f140107f902f1048394f1f096999bc149abf969720005537f7d572ef68d118a5dc74ba6ad489f00754439058d057123fa37ea2b9c52d65450c9e128c50c535e1c6065912ff1d03e510d66171862bdb9ea17276029961a7331888671b82fedde08b352681cdee8ad133970bd0c9769eeb1194872ebb1cc1364cacb879f42dbac989454b40ff9f45ade60b51a7fb4f2eb7d7f9c4e464a580826c39d7aed28ec73f3104c34666d6fe0fb88a9996c69d4f382b46527023966060499fa19aa2fbbb6b4306ca2a28ff0e61ed47582ece796629ff4b08104ff4e9214d4d2fa7b09ab5143da5ffa72c1d92efc4951179e3fce48baaf93d43756e117ba91adcb30a8ce78bb771988523b9539453bcfbef8a256d2ac57a0b3715835e41de680f7fcfb5ee6d53984a7a1388f099def060a1760cbb3157e97d3efc55b712801a5f21a499f11bb9d33188ea4f055bed3b8e77ad8ed01b06fe56fbe2a1213e8276f1c884b67df9e8feaa5e442efa9835e48063c15a649e109974c7d8deb137b95176c1a067cde11a87fbb11b6744ef53c13c2c64e9cdbae50fc5322159e3954230ccdcf76661757497efeae3809de06e3bde7df40c8b33be17fda48006e7dec19ea077fc8779efc2276223f6c8c375147680961322de87f195812e33dbb66af9f9cf4ef6bde3c7b2f209f25e3b12f45656b06a8d4523d42c1dc7cbd54c9ea789eb6edb39b73ab00607cc61d0bbd10753f63cec0c624410a1a58ea61ffef011a94ef5d51522e4ba2f384d31cea14092d0e482581ed6f29c7b4ecca1caf97e02715ad3feab301fa2f96eb23dc6af89cc44589274df89041d2a56d6cdb3eaa7e93cad1a8df00d9c5f775b0a5ae5013b42f71db8902c54b9f2d8fad4d70d55f4f67061c8f65df46b36acfc40e13c4b199e07c7b9112f4f2a54b09c0b838a8921367ef56787d88a59e2aec8204c1657b4e77e39aef29497c567a229046c46623f0fe123543374c7d87b2939bc24d7af6488f9d68d9ba3d2d4697894da1c10088b59e088197f2c2c8d3ee2a4e593408fa67b14863ba08cab14a06cfdc72b1aab421209148c282adf7157593a7a493d852ae2fc204c50b0b827f0f40a14563c2f1c7f6a0870254f8407c6985382c95d4d9545ca1e923474278064bcf864b52083d83042ff30b8ce61d1a980cdca4255a62cf622a2fd125091b3661c8524566409e9a75a5172db26bbea719f1553cb1765cb557bd6ad7718265be2e27b593ccc842234b8cd33ed02c9b9c4e8503eb53fa1312a8a87662f31dc1b49bf54f33dd8f1e8d0e05273d3a684b71fcf6f4d984f038ad1025ab1fed302fe70410ddcae830afadcc6c41a6e9ddf491fa00e84e14fea669d806337c99f228fad61283656329393c4e0567a2245c3f8e080696e96f785bac1b2349654df10a30af21919642154152462054e303d0583c4627b57ee6c9be91033f0f662d3a0d9446305a848d1d6553126467706636c374a9dc7bff32b3bb91c860ddd43e121626cfcda59bcd27035b071e6eff676a8121580e677d2e3b24fa8ae82de77d12869a29357fde8e40dae846a12e840108ebde0b17d32e4ab55d2315ccb515a80863924137e49bc0d555387866af17db9b689d89d4fdccbfe1349e0afc8e056555751ade2a22885a00ba90c4cba174bb491fee50506755ebb999a0fbc10215ea4e859a40121ced091436ec83d3497cc5c565d209964332131c994d2461f853ca8055f7b1856fcbb4209f4ff1c1540488e8e8682b0db134407f997e3132e0eb827d228674d9128ba27a0b1975cdbcefa967149da5081f32f076935c01e1d1a5e776931493e2682fe830a2bc5472ac9d5795b2774589f6b4675d04b259c2d85903037630f510a65370c56d4c880f8faa1b847c901041eca461f6cb10187ec3222f1ffd2617e6a39de81472295f568ac2f058a8fa8acb8a7e2acf41f39cb0e404aedb1d0488d1d5fdc475ecc48e56d42655f79afbfb236be122805b54b46381b3bd5a39857a6d345b485b61bd45d7d61ea8678c9b062804b5b2618c576f82b1f988604b8ec14583ddd66752350fe1059d60c7f0f13ce0fce4de4bf7117743197c2bb483d0b6448e92d07fe54631a5906fc7b45da9caf8678b6a74c32e5ab4cffdfb124ccf1fb5f0639fb498681547b015c93732311f1705722eedb953b0af55298acf7cd2fe4e2d9804e99ca85ebc68c512f609ccff33b093f601353173d25cab14d189d9e1c42853945cbb82cc8b1d7c0a95d7229c65ca2ee156983519b266075c595030f827dc8fc82658196a0a91a47e3167252eea94bc8ab4da6af418fc1bcdb82bf836815554dfc62ac2e2363eb51bb481a494554d9a7bc8ca91abbbeb695c33efa67ccdd2ffa9b3a10e2c9139e42e4c6d36263726a225bdc95dc1a1581077cc13d17a5f2d06df7d60e17bbf51eb9e9437126731f7ac53cb36999c4cec77996900d5c4d10236ecb23733a5f1f1bb37f9c0fc77fb2ca99e8d6f7d8703ce575d540293b5cb86ee440868a2b59b24f33221a2336f675a883252af142b3e89fae4db5536b7ef593850692dadaf50763906ae054583c0ff4b10c1ab762ebdfcdcd0faf64d78e68675052fe4ff645b0d97a7cd0a9ce23f90744cda173266163a256bbc1088dd92eb83700e4cd46b11023631253a612ff1467d7492fa92d3c4bfb34bd9ad1c76fd9e39f694a3b86b5cf8f8a273d74ef4149f925a0b7748bcc002e58ad1625a0e204aea095a08c4441bdd5af126d9db42a3d2414cfc931d79cb512bc5176a994e197a61f46708f305cb2dcbd05bf0b5e05e30585ee942203ae5e9a155e5c8ae16e737884049867358442d2f9cd9b082b68b8fe1411543a692d4ef60d5e936b79d214b0aec2a156923557995e7ef2e83ad430c10cf11c0bc8498012c204883718f1cdd8fb64e00fc34afa73710a0a312863f6b06a493788313a9d60995e7bce4662f5a31e3e753d9f96f5cff89940a8c4accc03c4b1db99677d4af57620f17ce1f62331d23157c736c5174b719bec8b0d35a3775e09410e3ed6990994febb3d624a1312baafa5d3c4c477f7d3e2160c9dab079c38713cc445c8519f965f6cefe80e8f6dd25270beaa613072046d50dacde962f3b7ffc47e2d1b415dc52951a654da6d48035003a376b00ff5080017be9068292d73bd37178d550c9faf70fb257439278b99884cad91fbf914e1da629ffedb7740d25b87f09ce87ce65f2b2c72a93e887413071bbb822f2cbd61758e3073ab9293352fefa1d36776d964df14b549f82014eda17e6d8a9419734d38bbda1a96a05127a8403ddfe4abd64c15da85b56cdddf32dd96f6086efaec2b0a8a5d0b56c75fdfc8d55f493bf75e393c0f3770af1a7bf9eb2c7d8b1f0bb1ef953277ebed31a246f2d947ddaca4a84188c0884b8304485fe35e37c47df8637ef912b48da8742447a2cb51ebb7252e33a7d4c3d38cc936cf335f147b269cdd6adb8ce3fa72ecee1c5e80d7fda7e24e2074067b47f1a4a4b853b3a8d8f3c368b4c3ede853a6d20fff843733a47a1a0a7b2d0f0688a33987940bef935da3f715c9db3af69646219516341c4b297fd5c7525aecbe4a3fe0372382a32e8bc6c5175e11b68e3b314bb1be9617abb34c996a39e756af7cacd3bf7867d3cdb918c8b12b76ad6aa6634375f8900e2faab32a044af18eed2c80468b94cb8791fc25bd547e362e98d346303178df88a4c3f1c3064f52f1274b41e5720b4efb96e2c2b62848ecfe2492aad058e62ccf27cbd975b2750e16961b11a9139109699fb5f03a0abf11be33d58bd235e8f4d60a764b876ffcae6c2e7c624b0d6f37ff6db02177f20bcd5401e9aaf0fc7019798465aeed4593dd3af693c2f8a1810563c42522273533dd2b2e206959002c292eebb108005ffe12e06fadbd9cf0049a2a1e92367b5a01b1ac4f9036bdada8a1b2b91e5783face895596e82a62d68ed9b46be501260887ec35cea9e635fbdd7c086cbf11fa6c29517971feb4d3e20f2ff625d49fc5fa60c51c586bf079af250f41dcf2d6fac8de4d05ba1bdbb4dd15be49350a01fb137e32e155d6db7f5ff0bf0bafe6b1eb31c514db51589d0f6e2e94d51fd5bf2bff427bc3fbed0df502849268e0af200a8cdfe98c90822ef9b2cd0443f30bae40ec857da596a85853a2ce7d8d81dc59323626a3c576ef75d1caf657b401c968209c2c4d8baa02d3d51aa7f179959cb635c6e51808a8cc221061ecf64c71fcf34ffa5b6fb929b74e45fac3c9aee41cc134b7e06c67b1e23d8c4c37a238aa73733023f5cd7754065a0c79411bb2690ac2568b56accd139315b774b47aa6c37303df28c5989f982f24514641b52b07f641701af1d62aa0025d2e7f7fa68e450a2782958bd2003a19084a15f4144702dc70703e858693fdd2955a8c18ab0f2f66d024bd2f4cd256c3448dbb8e068248ba4f9a8cb3c549341bce5be6b05c56c51e3ceee09f4f3151cd5b429dd36c95c66b3a66e5b5c3654e4e32fa36280ee25a945e33c1d9f1863e9318c62054eba8f5b5c44456daea0917cd9d2bcb4e4534ae88cbdcb9ae78da61fb4ef8cf3b26455e467b2cf84d164972303885343384d076dd51b5c9ddfec20a9352f4821a8ab1cf147fd9c034399dbdd45e1b21c382002efdfc515939c2a71140e859bac86255edeb5cb","link":"/posts/7e709362/"},{"title":"加密文章测试","text":"嗨，请准确无误地输入密码查看哟（密码：123456）！ 42401e656a30ed09e8e3b0fbe2fbd18ae1b8c2138de0b629bd1233cbc0cc80918b020088b54c79621b8ef9a9af7b0f06b4f358e8c86ef99d097fb161589581b453752da7da2e21aa4d35b94c835c62d1204ab327d5d9241d6be3c6b4b1e68d3697229826ffa52b53920e92cbe496af209269f803aa7450ba136338b0e891ba54f6fe48d0d23c1ba5b981305fdee3badd054b7ad20712af650adf010b25c3fa117b769979c2ef7a2ccccee14b24ed84530b911e7b68c43d9f4592ba8687b2c7fb","link":"/posts/7e709353/"},{"title":"git的基本操作","text":"git init #初始化git pull # 从远程仓库拉到本地git remote add origin https://gitee.com/privatecloud-1/privatecloud.git # 连接远程仓库git checkout zyj #切换分支 git add -A dashixun #上传文件git commit -m ‘1231’ # 备注git push #提交git clone -b “分支名字” 备用知识点 建项目着 如果想让其他人通过输入账号密码才能上传文件 则输入如下命令 (这些命令用不到)插入如下代码使项目中的组员每次修改数据都要输入账号和密码： git config –global user.name [username] git config –global user.password [userpassword] PS：想要保存密码，则需要插入如下代码： git config –global credential.helper store。 常用操作https://www.cnblogs.com/chenhuichao/p/9631754.html","link":"/posts/7eb35566/"},{"title":"关于爬虫自己所了解的功能梳理","text":"一.基础1.什么是爬虫网络爬虫（又被称为网页蜘蛛，网络机器人）就是 模拟客户端(主要指浏览器)发送网络请求，接收请求响应，按照一定的规则，自动地抓取互联网信息的程 序。原则上,只要是客户端(主要指浏览器)能做的事情，爬虫都能够做 2.爬虫的用途 数据采集 软件测试 爬虫之自动化测试 12306抢票 网站上的投票 投票网 短信轰炸 注册页面 web漏洞扫 3.虚拟环境Python 123456789101112131. 虚拟环境就是隔离的空间 1. virtualenvwrapper 管理 虚拟环境 2. pip install virtualenvwrapper-win -i 网址 3. virtual 虚拟 4. env 环境 5. wrapper2. mkvirtualenv envname(虚拟环境名) # 创建虚拟环境并自动切换到该环下3. workon 虚拟环境名 激活虚拟环境4. deactivate 退出虚拟环境5. lsvirtualenv 查看所有的虚拟环境6. rmvirtualenv 名字 删除虚拟环境7. pip freeze &gt; requirements.txt #安装 pip install -r requirements.txt8. mkvirtualenv normal -p D:\\Python3.8\\python.exe 4.爬虫数据的来源 去第三方的公司购买数据(比如企查查) 去免费的数据网站下载数据(比如国家统计局) 通过爬虫爬取数据 人工收集数据(比如问卷调查) 爬虫的概念：模拟浏览器发送网络请求，接收请求响应 5.爬虫的分类 通用爬虫 ：通常指搜索引擎的爬虫（https://www.baidu.com） 聚焦爬虫 ：针对特定网站的爬虫 针对特定领域 抓取特定数据 设计思路: 1. 确定URL，向服务器发起请求，获取响应 2. 数据解析—&gt; 目标数据 3. 持久化到本地 4. 金融量化分析/对冲 1. 给机器学习的模型提供训练数据 一般是以上两种 增量式爬虫 ：只爬取新产生的或者已经发生变化网页的爬虫 深网爬虫 ：隐藏在搜索表单或登录表单之后的数据，只有用户提交一些关键词 或登录才能获得的 Web 页面 6.B/S架构和C/S架构 B/S架构 B-&gt; Browser 浏览器 , S-&gt;Server 服务器 C/S架构 C-&gt;client 客户端, S-&gt;Server B/S架构是特殊的C/S架构 7.PHP不适合做爬虫 因为数据时效性比较差 时效性比较差比太适合爬虫 8.爬虫语言 PHP:并发能力差，对多进程和多线程支持不好，数据量较大时爬虫效率较低 C/C++:语言效率高，但是学习成本较大，对程序员的技术能力要求较高，目前还停留在研究阶段，市场需求低 Java:python爬虫的主要竞争对手，由于java的特点，代码臃肿，代码量大，维护成本高，开发效率低，但是目前市场上市场上需求量还是挺高 Python:语法简单，学习成本较低，对新手比较友好，Python语言良好的生态，大量和框架的支持是的python爬虫目前处于主导地位 9.robots协议 Robots协议（也称为爬虫协议、机器人协议等）的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。 Robots协议是一个道德层面的约定，爬虫作者尊不遵守完全看自己意愿。 9.网络协议 OSI七层: 应用层 会话层 传输层 网络层 数据链路层 物理层 TCP/IP五层 应用层 http/https,FTP文件传输协议 传输层 TCP/UDP 网络层 IP 数据链路层 ARP 物理层 以太网 HTT[协议和HTTPS TCP和UDP TCP面向链接的 基字节的流式传输，可靠 有序性 正确性 可靠性 可控性 UDP协议：面向无连接，用户数据报，不可靠 无连接，数据可能丢失或者循坏 报文小，传输效率高 吞吐量大的网络传输，可能在一定程度上承受数据丢失 服务器常见的端口 ftp:File Transfer Protocol 的缩写,即文件传输协议,端口 :21 ssh:Secure Shell的缩写，用于远程登陆会话，端口:22 MySQL：关系型数据库 ,端口:3306 MangoDB:非关系型数据库,端口27017 Redis:非关系型数据库,端口:6379 11. 第一次请求 URL介绍 URL作用式用于定位服务器资源的 请求过程: 客户端，通常指WEB浏览器或APP向服务器发起请求，服务器接收到请求进行处理，并向客户端发起响应 请求方法 请求头 请求体 状态码 响应体 网页基础 GET请求 url : 请求的链接 是一个字符串 headers : 请求头是一个字典 params:请求参数，字典 verify:禁止证书验证，SSLError POST请求 url headers data verify 12.JSON爬取和JSON的一些简单的解析规则 Python 1234567891011121314151617181920212223242526272829303132import csvfrom lxml import etreeimport requestsimport jsonimport rewith open('data.csv', 'w', encoding='utf-8') as f: writer = csv.writer(f, delimiter=',') writer.writerow(['标题', '内容', '图片', '时间'])for i in range(1,5): url = 'http://news.cctv.com/2019/07/gaiban/cmsdatainterface/page/china_%s.jsonp?cb=t&amp;cb=china'%i headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36' } ret = requests.get(url=url,headers=headers) ret.encoding = 'utf-8' res = re.findall(r'\\{.*\\}',ret.text)[0] ret = json.loads(res)['data']['list'] for i in ret: image = i['image2'] title = i['title'] brief = i['brief'] focus_date = i['focus_date'] with open('data.csv', 'a', encoding='gbk') as f: writer = csv.writer(f, delimiter=',') writer.writerow([title,brief,image,focus_date]) 二.爬虫的准备工作和爬虫的一些基础1. 安装 在指定环境下安装 pip install requests包(在需要爬虫的虚拟环境等安装此包) https://blog.csdn.net/aaronjny/article/details/77945329 （博客） 2.第一个简单的爬虫Python 12345678910111213141516import requestsbd = 'http://www.baidu.com'sg = 'http://www.sogou.com'res = requests.get(url=qc) # 请求页面# print(res) # 打印请求结果的状态码# print(res.text) # 打印请求到的网页的源码# print(res.content) # 二进制的网页源码res.encoding = 'urt-8' # 根据网页的编码格式更改with open('qianchengwuyou.html', 'w', encoding='utf-8') as f: f.write(res.text) with open('qianchengwuyou.html', 'wb') as f: # 以二进制写入，就不存在乱码 一般不推荐使用 f.write(res.content) 3.爬虫的一些语法 爬虫的一些发送请求 )!(/my_technology_blog_hexo/markdown_img/4cb3f14a08714f863659a7325ec7335.png) 5.requests的高级应用 上传文件 Cookie维持 ​ Python ​ ​ 1'Cookie' : '网页登陆信息的cookie的值' Session状态维持 SLL证书验证 ) 代理IP数据构建 ) 超时设置 ​ Python ​ ​ 1234567891011import requestsurl = 'https://www.baidu.com'headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36',}try: res = requests.get(url=url,headers=headers,timeout=0.01)except: print('超时') 构建Request对象 ) urllib简单介绍 ![urllib get](/my_technology_blog_hexo/markdown_img/urllib get.png) ![urllib post](/my_technology_blog_hexo/markdown_img/urllib post.png) re模块 6.利用urllib.request中的urlretrieve爬取图片Python 123456789101112131415import requestsfrom urllib.request import urlretrieveimport reimport jsonheaders = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}url = 'https://tu.enterdesk.com/'res = requests.get(url=url,headers=headers)src_list = re.findall(r'https://up.enterdesk.com/.*?\\.jpg',res.text)for src in src_list: name = src.split('/')[-1] urlretrieve(src,'./imgs/%s'%name) 7.正则 分组 分组 re模块 8.xpath的语法 xpath解析库 介绍 xpath安装 初体验–&gt;使用步骤 常规语法 9.BeautifulSoup库使用 Python 123soup = BeautifulSoup(res.text,'lxml') # 必须装好lxmltab = soup.find_all(name,atters,text) # 方法选择器 方法选择器 类选择器 嵌套选择器 获取文本和属性 string : 获取直接子文本,如果 有平行标签的话，返回的是一个None get_text() : 获取的是子孙节点的所有文本 element[‘attribute’] : 节点的属性 10.CSV写入文件和JSON写入 import csv with open('data.csv','w',encoding='utf-8') as csvf: ​ writer = csv.writer(csvf,delimiter=',') ​ writer.writerow(['标题','内容','姓名']) \\#这是 csv 的 **Code**- ```python import json lst = [] for i in range(100): d = {'name': '%s名字'%i, 'age': i*3} lst.append(d) with open('data.json', 'w', encoding='utf-8') as f: f.write(json.dumps(lst, ensure_ascii=False, indent=4)) # 这是 json的 11.selenium介绍 介绍 安装 推荐使用谷歌浏览器稳定版 三要素: 浏览器，驱动程序，selenium框架 驱动下载地址:http://chromedriver.storage.googleapis.com/index.html 安装 pip install selenium ​ Python ​ ​ 12345#测试from selenium import webdriverbrowser = webdriver.Chrome('./chromedriver.exe')browser.get('https://www.baidu.com') 常用操作 获取页面元素 交互操作 获取网页数据 Python 123js='window.scrollTo(0,document.body.scrollHeight)'brower.execute_script(js)# 滚动到最底下 Python 1234html = brower.page_sourcewith open('gushi.html','w',encoding='utf-8') as f: f.write(html) # 将源代码写入html中 11.雪球网站Python 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import requestsfrom lxml import etreefrom selenium import webdriverimport timedef jiexi(res): tree = etree.HTML(res) res_list = tree.xpath('//div[@class=&quot;AnonymousHome_home__timeline_VTo&quot;]/div//div[@class=&quot;AnonymousHome_home__timeline__item_3vU&quot;]') cc= [] for i in res_list: h3 = i.xpath('./h3/a/text()') zuozhe = i.xpath('.//div[@class=&quot;AnonymousHome_auchor_1RR&quot;]/a[@class=&quot;AnonymousHome_user-name_3wN&quot;]/text()') fabu_time = i.xpath('.//span[2]/text()') yuedu = i.xpath('.//div[@class=&quot;AnonymousHome_read_2t5&quot;]/text()') cc.append({ 'h3' : h3 , 'zuozhe' : zuozhe , 'fabutime' : fabu_time , 'yuedu' : yuedu }) return ccimport csvdef xiazai(res_list): with open('xue_qiu.csv','w',encoding='utf-8') as f: writer = csv.writer(f,delimiter=',') writer.writerow(['标题','作者','发布时间','点击量']) for i in res_list: try: username = i['h3'][0] zuozhe = i['zuozhe'][0] fabutime = i['fabutime'][0] yuedu = i['yuedu'][0] with open('xue_qiu.csv', 'a', encoding='utf-8') as f: writer = csv.writer(f, delimiter=',') writer.writerow([str(username),zuozhe, fabutime, yuedu]) except: zuozhe = i['zuozhe'][0] fabutime = i['fabutime'][0] yuedu = i['yuedu'][0] with open('xue_qiu.csv', 'a', encoding='utf-8') as f: writer = csv.writer(f, delimiter=',') writer.writerow(['无标题',zuozhe, fabutime, yuedu])def main(res): url = 'https://xueqiu.com/' headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36' } res_list = jiexi(res) xiazai(res_list)if __name__ == '__main__': brower = webdriver.Chrome() brower.get('https://xueqiu.com/') js = 'window.scrollTo(0,document.body.scrollHeight)' # 将页面滚动到最下面 for i in range(1, 6): if i &gt;= 5: brower.find_element_by_link_text('加载更多').click() print('点击了') else: brower.execute_script(js) . time.sleep(1) res = brower.page_source main(res) 12.模拟QQ空间登陆(没有涉及图片滑动解锁)Python 1234567891011121314151617181920from selenium import webdriver # 操作网页的包from time import sleep # 时间模块brower = webdriver.Chrome() # 实例化brower.get('https://qzone.qq.com/') # 确认要操作的网页brower.switch_to.frame('login_frame') # 进入页面的子页面，QQ空间brower.find_element_by_id('switcher_plogin').click()# brower.find_element_by_id('img_out_1559878380').click() # 快捷登陆，前提是需要登陆QQsleep(4)user = brower.find_element_by_id('u') # 账户输入框的ID值sleep(5)user.clear() # 清空账号框的内容，避免session存储了数据user.send_keys('1559878380') # 在输入框内输入指定的数据pwd = brower.find_element_by_id('p') # 定位密码框的ID值sleep(5)pwd.clear() # 清空密码框的内容pwd.send_keys('224949826..') # 输入密码框的内容sleep(5)brower.find_element_by_id('login_button').click() # 定位登陆按钮的ID值，并且点击 13.百度图片爬取,利用selenium (辉夜大小姐）Python 1234567891011121314151617181920212223242526272829import requests # 导包from selenium import webdriver # 操作网页的包from lxml import etree # 解析包import time # 导入时间模块from time import sleepbrower = webdriver.Chrome() # 实例化brower.get('http://image.baidu.com/') # 需要操作的操作brower.find_element_by_id('kw').send_keys('辉夜大小姐') # 获取搜索框的id值，利用send_keys输入指定值ret = brower.find_element_by_class_name('s_search') # 利用方法找到搜索按钮，ret.click() # 点击搜索按钮sleep(2) # 休息2sfor i in range(3): # 循环3次 js = 'window.scrollTo(0,document.body.scrollHeight)' # 页面向下拉到最底部 brower.execute_script(js) # 执行js代码 time.sleep(4) # 休眠4sres = brower.page_source # 将页面的HTML页面的源代码 抓取terr = etree.HTML(res) # 实例化xpathret_list = terr.xpath('//div[@id=&quot;imgid&quot;]/div//ul/li') # 匹配要抓取的数据headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}for i in ret_list: url_li = i.xpath('./@data-objurl')[0] res = requests.get(url=url_li,headers=headers).content name = url_li.split('/')[-1] with open('./imgs/%s'%name,'wb') as f: f.write(res) 14.谷歌无头浏览器 三.多线程爬虫1.并发和并行 并发:同一时间段内共同执行 时间片轮转法:给每一个程序一个时间段，一点一点执行，可能导致结果出错(不加锁的情况下) 多线程可能会导致数据不安全(上锁可以避免此情况) 并行：同一时刻一起执行 2.爬虫架构图 URL队列 爬虫线程类 data队列 数据解析的线程类 3.多线程爬虫实例(存储的是csv格式)Python 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114import threadingimport requestsfrom lxml import etreefrom queue import Queuefrom threading import Lockimport csv#封装爬虫类(负责数据采集的)class CrawlThread(threading.Thread): def __init__(self,crawlName,pageQueue,dataQueue): super().__init__() self.crawlname = crawlName # 爬虫名，用于监控爬虫的运行过程 self.pageQueue = pageQueue # url的队列，用于存放url self.dataQueue = dataQueue # 存放响应数据 self.headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36' } # UA伪装 def run(self): base_url = 'http://xiaohua.zol.com.cn/lengxiaohua/%s.html' # 定义一个基准的url while True: try: page = self.pageQueue.get(block=False) # block参数代表队列参数是否阻塞 # 如果block = Ture 代表阻塞，如果队列为空，在get时，会产生阻塞，知道队列有元素可以get 时为止，可是获取元素 # block = False 代表不阻塞，如果队列为空，get的操作会抛出异常 print('%s正在爬取数据'%self.crawlname) # 请求页面获取响应数据 res = requests.get(url=base_url%page,headers=self.headers).text # 将响应数据提交给dataQueue，以便后续的解析的线程取用 self.dataQueue.put(res) print('%s提交数据完毕'%self.crawlname) except: break#解析类(负责数据的解析和存储)class PaarseThead(threading.Thread): def __init__(self,p,dataQueue,lock): super().__init__() self.PaarseName = p self.dataQueue = dataQueue self.lock = lock def run(self): while True: try: html = self.dataQueue.get(block=False) print('%s正在解析数据'%self.PaarseName) self.parse(html) print('%s数据数据解析完毕'%self.PaarseName) except: break def parse(self,html): # 具体的解析过程 tree = etree.HTML(html) res = tree.xpath('//li[@class=&quot;article-summary&quot;]') self.csv_t() for i in res: title = i.xpath('./span[2]/a/text()')[0] href = i.xpath('./span[2]/a/@href')[0] content = i.xpath('.//div[@class=&quot;summary-text&quot;]/text()') d = {'title' : title,'href':href,'content':content} with self.lock: self.save(d) def csv_t(self): with open('data.csv','w',encoding='utf-8') as f: writer = csv.writer(f,delimiter=',') writer.writerow(['标题','链接','内容']) def save(self,d): with open('data.csv','a',encoding='utf-8') as f: writer = csv.writer(f,delimiter=',') writer.writerow([d['title'],d['href'],d['content'][0]])def main(): pageQueue = Queue() # 存放url的队列 dataQueue = Queue() # 存放响应数据的队列 &quot;&quot;&quot; 发起请求和获取响应 &quot;&quot;&quot; for i in range(1,20): pageQueue.put(i) # 向url队列添加列表 CrawlName = ['爬虫一号','爬虫二号','爬虫三号'] crawlList = [] for var in CrawlName: #实例化爬虫线程对象 c = CrawlThread(var,pageQueue,dataQueue) c.start() # 开启线程 crawlList.append(c) for c in crawlList: # 将线程统一执行join操作 c.join() print(dataQueue.qsize()) # 查看dataQueue队列中有几条数据 &quot;&quot;&quot; 解析数据 &quot;&quot;&quot; lock = Lock() PaarseName = ['解析1号','解析2号','解析3号'] PaarseList = [] for p in PaarseName: cc = PaarseThead(p,dataQueue,lock) cc.start() PaarseList.append(cc) for pl in PaarseList: pl.join()if __name__ == '__main__': main() 4.多线程爬取辽宁工程Python 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596from lxml import etree # 导包lxml包import requests import pymongofrom queue import Queueimport threadingfrom threading import Lockconn = pymongo.MongoClient('127.0.0.1',27017) # 实例化mangodb数据库db = conn.ztb # 要使用的数据库，如果该数据库则创建新的数据库table = db.lngc # 使用该表，如果没有该表，则创建该表class CrawlThread(threading.Thread): # 爬虫类 def __init__(self,crawname,urlqueue,dataqueue,headers): super().__init__() # 使init不报黄 self.crawname = crawname # 将当前爬虫(爬虫1号or爬虫2号等) 传值过来，方便显示 self.urlqueue = urlqueue # 将url队列传过来 self.dataqueue = dataqueue # 响应值队列 self.headers = headers # 请求头 def run(self): while True: # 无限循环 try: print('%s正在抓取数据页面'%self.crawname) # 在后端显示当前是几号爬虫在爬取数据 res = requests.get(url=self.urlqueue.get(block=False),headers=self.headers).text # 将url队列中的路由取出来，队列的get操作每次只获取一个数据 print('%s正在抓取完毕'%self.crawname) self.dataqueue.put(res) # 将获取到响应数据 添加到响应数据队列 except: break # 因为 get()有 block=False 如果取值下一个没有数据 则报错 报错就会终止该循环class ParseThead(threading.Thread): # 解析类 def __init__(self,parse,dataqueue,lock): super().__init__() self.parse = parse # 将当前解析对象赋值给self.parse self.dataqueue = dataqueue # 将响应数据队列传过来，注意 此时的队列已经是有数据 self.lock = lock # 锁 def run(self): while True: try: print('%s正在解析数据'%self.parse) ret = self.dataqueue.get(block=False) # 将队列中的数据取出来，一次只能取一个 print('%s解析数据完毕'%self.parse) self.parsejiexi(ret) # 将获取的值作为实参传给函数parsejiexi except: break def parsejiexi(self,cc): tree = etree.HTML(cc) # 实例化etree ret = tree.xpath('//ul[@id=&quot;showList&quot;]/li') # 解析页面，获取当前页所有的li for i in ret: # 循环所有的li title = i.xpath('.//a/font[1]/text()')[0] # 获取每个li中的要获取的值 href = i.xpath('.//a/@href')[0] laizi = i.xpath('.//a/font[2]/text()')[0] biaoti = i.xpath('.//a/text()')[0] time = i.xpath('./span/text()')[0] d = {'title':title,'href':'http://lnzxzb.cn'+href,'laizi':laizi,'biaoti':biaoti,'time':time} # 将获取的值 存放在字典中，mongodb存储格式也是字典 所以直接可以添加到mogodb中 with self.lock: #开启锁，如果当前代码结束就解锁 self.mongodb_insert(d) # 调用数据持久化的函数 def mongodb_insert(self,d): # 数据持久化的函数 table.insert_one(d) # 将数据存储在数据库中def main(): urlqueue = Queue() # 实例化url队列 dataqueue = Queue() # 实例化响应队列 shouye_url = ['http://lnzxzb.cn/gcjyxx/subpage.html'] # 首页路由 yema = ['http://lnzxzb.cn/gcjyxx/%s.html'%page for page in range(1,51)] # 列表推导式 推导出50个页面 shouye_url.extend(yema) # 拆分添加 for i in shouye_url: # 将所有页面循环 urlqueue.put(i) # 将url添加到url队列中 headers = { 'user-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36' } # 表头 CrawlName = ['爬虫1号','爬虫2号','爬虫3号','爬虫4号','爬虫5号','爬虫6号','爬虫7号'] # 随便写几个爬虫 CrawList = [] # 做一个空列表 for craw in CrawlName: # 循环列表 因为CrawName 有7个 所以开了7个线程 c = CrawlThread(craw,urlqueue,dataqueue,headers) # 实例化线程 c.start() # 开启线程 CrawList.append(c) # 将线程的变量存储到空列表中 for c in CrawList: c.join() # 等待线程结束才关闭主线程 # 下面的这些和上面一个意思 就是 开启的线程是 4 个线程 ParseName = ['解析1号','解析2号','解析3号','解析4号'] ParseList = [] ParList = [] lock = Lock() for parse in ParseName: p = ParseThead(parse,dataqueue,lock) p.start() ParseList.append(p) for p in ParList: p.join() # print(dataqueue.qsize())if __name__ == '__main__': main() 四.第三方打码平台(超级鹰)1.打码平台代码Python 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/usr/bin/env python# coding:utf-8import requestsfrom hashlib import md5class Chaojiying_Client(object): def __init__(self, username, password, soft_id): self.username = username password = password.encode('utf8') self.password = md5(password).hexdigest() self.soft_id = soft_id self.base_params = { 'user': self.username, 'pass2': self.password, 'softid': self.soft_id, } self.headers = { 'Connection': 'Keep-Alive', 'User-Agent': 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)', } def PostPic(self, im, codetype): &quot;&quot;&quot; im: 图片字节 codetype: 题目类型 参考 http://www.chaojiying.com/price.html &quot;&quot;&quot; params = { 'codetype': codetype, } params.update(self.base_params) files = {'userfile': ('ccc.jpg', im)} r = requests.post('http://upload.chaojiying.net/Upload/Processing.php', data=params, files=files, headers=self.headers) return r.json() def ReportError(self, im_id): &quot;&quot;&quot; im_id:报错题目的图片ID &quot;&quot;&quot; params = { 'id': im_id, } params.update(self.base_params) r = requests.post('http://upload.chaojiying.net/Upload/ReportError.php', data=params, headers=self.headers) return r.json()if __name__ == '__main__': chaojiying = Chaojiying_Client('1559878380', '224949826..', '902931') #用户中心&gt;&gt;软件ID 生成一个替换 96001 im = open('a.jpg', 'rb').read() #本地图片文件路径 来替换 a.jpg 有时WIN系统须要// print (chaojiying.PostPic(im, 1902)) #1902 验证码类型 官方网站&gt;&gt;价格体系 3.4+版 print 后要加() 五.反爬1. selenium自动化操作中检测到security-check问题(cookie时效性差的问题)Python 12345from selenium.webdriver import ChromeOptions # 可以避免浏览器检测的包options = webdriver.ChromeOptions() # 实例化options.add_experimental_option('excludeSwitches', ['enable-automation']) # 给实例化的属性添加一个键值对，这个键值对就可以避免网站检测到是否是爬虫browser = webdriver.Chrome(options=options) # 将该属性传进来# 最新版(79版)不能使用需要降版本到78版本 六.Scrapy框架1.安装 Python 1http://www.lfd.uci.edu/~gohlke/pythonlibs/ # twisted的安装网页,目前已经安装好了 2.五大核心组件与数据流向 Scrapy Engine 引擎 负责组件间通信 Item Pipeline 管道 负责数据持久化 Downloader 下载器 负责爬取数据 Scheduler 调度器 负责调度请求 Spider 爬虫 定义了爬取行为，数据解析规则，提交item给管道 Downloader Middlewares 下载中间间 Spider Middlewares 爬虫中间件 3.创建一个项目Python 1234scrapy startproject ztb # 创建scrapy项目名为ztbscrapy genspider tb baidu.com # 定义爬虫名字scrapy crawl tb --nolog # 启动爬虫项目， --nolog为不显示日志typ = r.xpath('./p/a/font[1]/text()').extract_first() # xpath解析数据为一个对象需要使用extract_first()取出第一个值 4.获取详情页Python 1234567891011121314151617181920212223class XhSpider(scrapy.Spider): name = 'xh' # allowed_domains = ['baidu.com'] start_urls = ['http://www.jokeji.cn/list_%s.htm'%page for page in range(1,3)] def com_parse(self,response): # 接收到详情页的响应 item = response.meta['item'] # 将函数parse中的meta中的item取出来赋值给item content = ''.join(response.xpath('//span[@id=&quot;text110&quot;]//text()').extract()) # 将所有文本写入 并且利用字符串的常见操作join拼接到新的字符串中 item['content'] = content # 将这个字符串储存在itmen的对应的key中 yield item # 返回item值 def parse(self, response): li_list = response.xpath('//div[@class=&quot;list_title&quot;]/ul/li') for li in li_list: title = li.xpath('./b/a/text()').extract_first() times = li.xpath('./i/text()').extract_first() liulan = li.xpath('./span/text()').extract_first() url_c = 'http://www.jokeji.cn' + li.xpath('./b/a/@href').extract_first() item = XiaohuaItem() item['title'] = title item['times'] = times item['liulan'] = liulan yield scrapy.Request(url=url_c,callback=self.com_parse,meta={'item':item}) # 用新的url发送请求，并且利用callback定位到新的函数中，并且把meta的值 以字典的形式传过去 5.动态获取数据scrapy框架和selenium框架结合使用(网易新闻)Python 123456789101112def process_response(self, request, response, spider): # 下载中间件的拦截全部响应 if response.url in spider.start_urls: # 判断当前路由是否是静态页面的url bowor = spider.bower # 从spider中导出实例化的selenium对象 bowor.get(response.url) # selenium访问url js = 'window.scrollTo(0, document.body.scrollHeight)' for i in range(2): bowor.execute_script(js) time.sleep(2) html = bowor.page_source # 获取网页源码 return HtmlResponse(url=bowor.current_url,body=html,request=request, encoding='utf-8') # 返回一个response对象 current_url为selenium当前访问的url,body为网页源码 HtmlResponse需要导包 from scrapy.http import HtmlResponse return response# 需要打开settings的下载中间件，切记别打开错误的中间件，不然中间件不会被启用 6.数据持久化 7.数据持久化的MongoDB的正规写法(管道)Python 123456789101112131415161718192021import pymongo # 导包，需要mongoclass QuanzhanPaquPipeline(object): # 管道中自带class类 def __init__(self, mongo_uri, mongo_db): # 初始化 self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls, crawler): return cls( mongo_uri = crawler.settings.get('MONGOURI'), # 在settings中配置的文件 mongo_db = crawler.settings.get('MONGODB') # uri为数据库地址，db为这次的库名 ) def open_spider(self): # 启动爬虫时，该函数执行 连接上数据库(还有一个start_spider方法) self.client = pymongo.MongoClient(self.mongo_uri) # mongo连接 self.db = self.client[self.mongo_db] # 创建数据库 def process_item(self, item, spider): # 添加数据的时候启动 self.db['qz'].insert_one(dict(item)) # 将数据写入到qz的表中 return item def close_spider(self, spider): # 爬虫结束时运行 self.client.close() # 关闭数据库 9.全栈数据爬取Python 123#创建项目的时候scrapy startproject 项目名 # 创建项目scrapy genspider -t crawl 爬虫名 baidu.com # 创建爬虫名 10.框架封装cookiePython 12345678910import scrapycookoe_str = '一个网页的cookie值'cookies = dict()from item in cookie_str.split(';') # cookie值中每个key和value中有；分开 key,value = item.split('=',1) # 只分割一次 cookies[key] = valueclass 爬虫(): ...... def start_request(self): yield scrapy.Request(url=self.start_urls[0], cookies=cookies) 七.中间件 Python 1234# 在middleware中,中间件的函数意思process_request : 拦截的是非异常请求,一般可以在这里更换UA和代理IPprocess_response : 拦截的是所有响应，一般在这里可以配合selenium框架使用动态页面的抓取process_exception : 拦截的是异常请求 1.UA池Python 12345from fake_useragent import UserAgent # 导包ua = UserAgent() # 实例化UserAgent方法ua_list = [] # 创建一个空列表for i in range(200): # 循环200次，获取200个UA ua_list.append(ua.Chrome) 2.拦截之后更换IPPython 1234def process_request(self, request, spider): # 在middlewares中，拦截非异常请求 request.meta['proxy'] = 'http://60.13.42.175:9999' # 前面为固定格式，后面写需要代理的ip request.meta['proxy'] = 'http://%s'%(random.choice(代理ip池)) return None 3.拦截之后更换UAPython 12345def process_request(self, request, spider): # 在middlewares中，拦截非异常请求 request.headers['User-Agent'] = '' # 前面为固定格式，后面写需要的UA request.headers['User-Agent'] = '%s'%(random.choice(UA池)) return None# 然后可以在response函数中print(response.headers)打印显示 八.增量式爬虫和深度爬虫1.增量式爬虫Python 12345# 在提交请求或者保存数据的时候，判断是否存储过该url或者数据# 利用redis数据库的集合特点，如果没有返回1并将数据存储在数据库中# from redis import Redis 导包# 实例化一个Redis# ret = conn(实例化的对象).sadd('key','value')","link":"/posts/468ef90b/"},{"title":"python内置的内存管理机制","text":"在Python中是如何管理内存的Python有一个私有堆空间来保存所有的对象和数据结构。作为开发者，我们无法访问它，是解释器在管理它。但是有了核心API后，我们可以访问一些工具。Python内存管理器控制内存分配。 另外，内置垃圾回收器会回收使用所有的未使用内存，所以使其适用于堆空间。 一、垃圾回收：python不像C++，Java等语言一样，他们可以不用事先声明变量类型而直接对变量进行赋值。对Python语言来讲，对象的类型和内存都是在运行时确定的。这也是为什么我们称Python语言为动态类型的原因(这里我们把动态类型可以简单的归结为对变量内存地址的分配是在运行时自动判断变量类型并对变量进行赋值)。 二、引用计数：Python采用了类似Windows内核对象一样的方式来对内存进行管理。每一个对象，都维护这一个对指向该对对象的引用的计数。当变量被绑定在一个对象上的时候，该变量的引用计数就是1，(还有另外一些情况也会导致变量引用计数的增加),系统会自动维护这些标签，并定时扫描，当某标签的引用计数变为0的时候，该对就会被回收。 1 对象存储 在Python中万物皆对象 不存在基本数据类型，0, 1.2, True, False, “abc”等，这些全都是对象 所有对象, 都会在内存中开辟一块空间进行存储 2.1 会根据不同的类型以及内容, 开辟不同的空间大小进行存储 2.2 返回该空间的地址给外界接收(称为”引用”), 用于后续对这个对象的操作 2.3 可通过 id() 函数获取内存地址(10进制) 2.4 通过 hex() 函数可以查看对应的16进制地址 class Person: pass p = Person()print(p)print(id(p))print(hex(id(p))) 打印结果 &lt;main.Person object at 0x107030470&gt;44126055520x107030470对于整数和短小的字符, Python会进行缓存; 不会创建多个相同对象 此时, 被多次赋值, 只会有多份引用 num1 = 2num2 = 2print(id(num1), id(num2)) 打印结果 4366584464 4366584464容器对象, 存储的其他对象, 仅仅是其他对象的引用, 并不是其他对象本身 4.1 比如字典, 列表, 元组这些”容器对象” 4.2 全局变量是由一个大字典进行引用 4.3 可通过 global() 查看 2 对象回收 2.1 引用计数器 2.1.1概念 一个对象, 会记录着自身被引用的个数 每增加一个引用, 这个对象的引用计数会自动+1 每减少一个引用, 这个对象的引用计数会自动-1 引用计数+1场景 1、对象被创建 p1 = Person()2、对象被引用 p2 = p13、对象被作为参数，传入到一个函数中 log(p1) 这里注意会+2, 因为内部有两个属性引用着这个参数4、对象作为一个元素，存储在容器中 l = [p1]引用计数-1场景 1、对象的别名被显式销毁 del p12、对象的别名被赋予新的对象 p1 = 1233、一个对象离开它的作用域 一个函数执行完毕时 内部的局部变量关联的对象, 它的引用计数就会-14、对象所在的容器被销毁，或从容器中删除对象查看引用计数 import sys class Person: pass p1 = Person() # 1 print(sys.getrefcount(p1)) # 2 p2 = p1 # 2 print(sys.getrefcount(p1)) # 3 del p2 # 1print(sys.getrefcount(p1)) # 2 del p1print(sys.getrefcount(p1)) #error，因为上一行代码执行类p1对象已经销毁 打印结果 232循环引用 循环引用class Person: pass class Dog: pass p = Person()d = Dog() p.pet = dd.master = p对象间互相引用，导致对象不能通过引用计数器进行销毁 手动触发垃圾回收，挥手循环引用 import objgraphimport gc class Person: pass class Dog: pass p = Person()d = Dog() p.pet = dd.master = p del pdel d gc.collect() #手动触发垃圾回收 print(objgraph.count(“Person”))print(objgraph.count(“Dog”)) 打印结果00","link":"/posts/89986499/"},{"title":"python的数据结构","text":"关于数据结构什么是数据结构？ 简单地说，数据结构是以某种特定的布局方式存储数据的容器。这种“布局方式”决定了数据结构对于某些操作是高效的，而对于其他操作则是低效的。首先我们需要理解各种数据结构，才能在处理实际问题时选取最合适的数据结构。 为什么我们需要数据结构？ 数据是计算机科学当中最关键的实体，而数据结构则可以将数据以某种组织形式存储，因此，数据结构的价值不言而喻。 无论你以何种方式解决何种问题，你都需要处理数据——无论是涉及员工薪水、股票价格、购物清单，还是只是简单的电话簿问题。 数据需要根据不同的场景，按照特定的格式进行存储。有很多数据结构能够满足以不同格式存储数据的需求。 常见的数据结构 首先列出一些最常见的数据结构，我们将逐一说明： 数组 栈 队列 链表 树 字典树（这是一种高效的树形结构，但值得单独说明） 散列表（哈希表） 数组数组是最简单、也是使用最广泛的数据结构。栈、队列等其他数据结构均由数组演变而来。下图是一个包含元素（1，2，3和4）的简单数组，数组长度为4。 每个数据元素都关联一个正数值，我们称之为索引，它表明数组中每个元素所在的位置。大部分语言将初始索引定义为零。 以下是数组的两种类型： 一维数组（如上所示） 多维数组（数组的数组） 数组的基本操作 Insert——在指定索引位置插入一个元素 Get——返回指定索引位置的元素 Delete——删除指定索引位置的元素 Size——得到数组所有元素的数量 面试中关于数组的常见问题 寻找数组中第二小的元素 找到数组中第一个不重复出现的整数 合并两个有序数组 重新排列数组中的正值和负值 栈著名的撤销操作几乎遍布任意一个应用。但你有没有思考过它是如何工作的呢？这个问题的解决思路是按照将最后的状态排列在先的顺序，在内存中存储历史工作状态（当然，它会受限于一定的数量）。这没办法用数组实现。但有了栈，这就变得非常方便了。 可以把栈想象成一列垂直堆放的书。为了拿到中间的书，你需要移除放置在这上面的所有书。这就是LIFO（后进先出）的工作原理。 下图是包含三个数据元素（1，2和3）的栈，其中顶部的3将被最先移除： 栈的基本操作 Push——在顶部插入一个元素 Pop——返回并移除栈顶元素 isEmpty——如果栈为空，则返回true Top——返回顶部元素，但并不移除它 面试中关于栈的常见问题 使用栈计算后缀表达式 对栈的元素进行排序 判断表达式是否括号平衡 应用场景：逆序输出，语法检查，进制转换 在我们日常编程中，括号都是成对出现的，比如“()”“[]”“{}”“&lt;&gt;”这些成对出现的符号 那么具体处理的方法就是:凡是遇到括号的前半部分，即把这个元素入栈，凡是遇到括号的后半部分就比对栈顶元素是否该元素相匹配，如果匹配，则前半部分出栈，否则就是匹配出错 将十进制的数转换为2-9的任意进制的数 我们都知道，通过求余法，可以将十进制数转换为其他进制，比如要转为八进制，将十进制数除以8，记录余数，然后继续将商除以8，一直到商等于0为止，最后将余数倒着写数来就可以了。 比如100的八进制，100首先除以8商12余4,4首先进栈，然后12除以8商1余4，第二个余数4进栈，接着1除以8，商0余1，第三个余数1进栈，最后将三个余数出栈，就得到了100的八进制数144, 队列与栈相似，队列是另一种顺序存储元素的线性数据结构。栈与队列的最大差别在于栈是LIFO（后进先出），而队列是FIFO，即先进先出。 一个完美的队列现实例子：售票亭排队队伍。如果有新人加入，他需要到队尾去排队，而非队首——排在前面的人会先拿到票，然后离开队伍。 下图是包含四个元素（1，2，3和4）的队列，其中在顶部的1将被最先移除： 移除先入队的元素、插入新元素 队列的基本操作 Enqueue()——在队列尾部插入元素 Dequeue()——移除队列头部的元素 isEmpty()——如果队列为空，则返回true Top()——返回队列的第一个元素 面试中关于队列的常见问题 使用队列表示栈 对队列的前k个元素倒序 使用队列生成从1到n的二进制数 链表链表是另一个重要的线性数据结构，乍一看可能有点像数组，但在内存分配、内部结构以及数据插入和删除的基本操作方面均有所不同。 链表就像一个节点链，其中每个节点包含着数据和指向后续节点的指针。 链表还包含一个头指针，它指向链表的第一个元素，但当列表为空时，它指向null或无具体内容。 链表一般用于实现文件系统、哈希表和邻接表。 这是链表内部结构的展示： 链表包括以下类型： 单链表（单向） 双向链表（双向） 链表的基本操作： InsertAtEnd - 在链表的末尾插入指定元素 InsertAtHead - 在链接列表的开头/头部插入指定元素 Delete - 从链接列表中删除指定元素 DeleteAtHead - 删除链接列表的第一个元素 Search - 从链表中返回指定元素 isEmpty - 如果链表为空，则返回true 面试中关于链表的常见问题 反转链表 检测链表中的循环 返回链表倒数第N个节点 删除链表中的重复项 树树形结构是一种层级式的数据结构，由顶点（节点）和连接它们的边组成。 树类似于图，但区分树和图的重要特征是树中不存在环路。 树形结构被广泛应用于人工智能和复杂算法，它可以提供解决问题的有效存储机制。 这是一个简单树的示意图，以及树数据结构中使用的基本术语： Root - 根节点 Parent - 父节点 Child - 子节点 Leaf - 叶子节点 Sibling - 兄弟节点 以下是树形结构的主要类型： N元树 平衡树 二叉树 二叉搜索树 AVL树 红黑树 2-3树 其中，二叉树和二叉搜索树是最常用的树。 面试中关于树结构的常见问题： 求二叉树的高度 在二叉搜索树中查找第k个最大值 查找与根节点距离k的节点 在二叉树中查找给定节点的祖先节点 字典树（Trie） 字典树，也称为“前缀树”，是一种特殊的树状数据结构，对于解决字符串相关问题非常有效。它能够提供快速检索，主要用于搜索字典中的单词，在搜索引擎中自动提供建议，甚至被用于IP的路由。 这些单词以顶部到底部的方式存储，其中绿色节点“p”，“s”和“r”分别表示“top”，“thus”和“theirs”的底部。 面试中关于字典树的常见问题 计算字典树中的总单词数 打印存储在字典树中的所有单词 使用字典树对数组的元素进行排序 使用字典树从字典中形成单词 构建T9字典（字典树+ DFS ）","link":"/posts/2ff1809f/"},{"title":"如何使用python+Vue.js+Django上传文件到七牛云","text":"使用python+Vue.js+Django异步前端通过api上传文件到七牛云​ 首先注册七牛云：qiniu.com，进入你的七牛云账号，打开秘钥页，记录下你的ak和sk ​ ​ 随后新建一个云存储空间，这里空间名字一定要记录一下： ​ ​ 此时我们用django写一个获取uptoken的接口，使用drf框架来写，注意别忘了安装七牛云扩展 pip install qiniu ​ 1234567891011#七牛云tokenfrom qiniu import Authclass QiNiu(APIView): def get(self,request): q = Auth('E2IZM3koC1GR1DUqJHactmixzdyZZhx0edBKqDsk','GDnMkvRoE_kFhCSuvdqQj0VcNsRDOHzYJJ_bVd0_') token = q.upload_token('redinnovation') print(token) res = {} res['uptoken'] = token return Response(res) ​ 访问django服务，确保每一次都会生成新的token,访问http://localhost:8000/uptoken/ ​ ​ 接口已经调试好，回到vue.js页面，添加一个上传控件 ​ 123{{ imgLoadPercent }} &lt;input @change=&quot;uploadInputchange&quot; id=&quot;uploadFileInput&quot; type=&quot;file&quot; &gt; ​ 123456data () { return { uptoken:'', imgLoadPercent:'',}} ​ 然后在methods里添加几个方法： ​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748get_token(){ this.axios.get('http://localhost:8000/uptoken/').then((result) =&gt;{ console.log(result); this.uptoken = result.data.uptoken; }); }, //触发input change事件 uploadInputchange(){ let file = document.getElementById(&quot;uploadFileInput&quot;).files[0]; //选择的图片文件 this.get_token(); this.uploadImgToQiniu(file); }, //上传图片到七牛 uploadImgToQiniu(file){ console.log(this.uptoken); const axiosInstance = this.axios.create({withCredentials: false}); //withCredentials 禁止携带cookie，带cookie在七牛上有可能出现跨域问题 let data = new FormData(); data.append('token',this.uptoken); //七牛需要的token data.append('file', file); axiosInstance({ method: 'POST', url: 'http://up-z1.qiniu.com/', //上传地址，华北的空间是up-z1.qiniu.com data: data, timeout:30000, //超时时间，因为图片上传有可能需要很久 onUploadProgress: (e)=&gt; { //imgLoadPercent 是上传进度，可以用来添加进度条 var complete = (e.loaded / e.total); if (complete &lt; 1) { this.imgLoadPercent = (complete *100).toFixed(2)+ '%'; } }, }).then(data =&gt;{ console.log(data); this.imgLoadPercent = '100%'; }).catch(function(err) { //上传失败 }); } ​ 最后，如果上传成功后，七牛云接口会返回文件的key ​","link":"/posts/ac1d54ea/"},{"title":"三方登录","text":"第三方登陆1.微博登陆 vue向接口发送请求 Code 1'https://api.weibo.com/oauth2/authorize?client_id=297351690&amp;redirect_uri=http://127.0.0.1:8000/weibo_callback' 微博回调接口 Python 12345678910111213141516171819202122232425262728293031323334353637383940# 新浪微博回调def wb_back(request): # 获取code code = request.GET.get('code') # 定义微博认证地址 data = { 'client_id': '297351690', 'client_secret': '8e24e86fd5dfa8d95675316bd969f9f1', 'grant_type': 'authorization_code', 'code': code, 'redirect_uri': 'http://127.0.0.1:8000/weibo_callback' } url = 'https://api.weibo.com/oauth2/access_token' res = requests.post(url, data=data).text res = json.loads(res) # return HttpResponse(res['uid']) # 获取新浪微博用户名 result = requests.get(url='https://api.weibo.com/2/users/show.json', params={'access_token': res['access_token'], 'uid': res['uid']}) result = json.loads(result.text) # print(result) # 判断该用户曾经是否登陆过 user = User.objects.filter(username=str(result['name'])).first() sina_id = '' user_id = '' if user: sina_id = user.username user_id = user.id else: # 手动创建账号 User.objects.create(username=str(result['name']), password='') sina_id = result['name'] user = User.objects.filter(username=str(result['name'])).first() user_id = user.id print(user_id) return redirect('http://localhost:8080/?sina_id=' + str(sina_id) + '&amp;user_id=' + str(user_id)) 2.钉钉登陆 vue发送接口请求 Code 1'https://oapi.dingtalk.com/connect/qrconnect?appid=dingoaty1hbauyiitjsip2&amp;response_type=code&amp;scope=snsapi_login&amp;state=STATE&amp;redirect_uri=http://127.0.0.1:8000/dingding_callback' 回调接口 Python 12345678910111213141516171819202122232425262728293031# 钉钉回调def ding_back(request): code = request.GET.get('code') t = time.time() # 时间戳 timestamp = str((int(round(t * 1000)))) appSecret = 'kFeBIcAi-P5VNeA_2EIjARQu6dYct2h-3iiTUNpPEBuWjN3efumu2BfLhBgGVttz' # 构造签名 signature = base64.b64encode( hmac.new(appSecret.encode('utf-8'), timestamp.encode('utf-8'), digestmod=sha256).digest()) # 请求接口，换取钉钉用户名 payload = {'tmp_auth_code': code} headers = {'Content-Type': 'application/json'} res = requests.post('https://oapi.dingtalk.com/sns/getuserinfo_bycode?signature=' + urllib.parse.quote( signature.decode(&quot;utf-8&quot;)) + &quot;&amp;timestamp=&quot; + timestamp + &quot;&amp;accessKey=dingoaty1hbauyiitjsip2&quot;, data=json.dumps(payload), headers=headers) res_dict = json.loads(res.text) user = User.objects.filter(username=str(res_dict['user_info']['nick'])).first() dingding_id = '' user_id = '' if user: dingding_id = res_dict['user_info']['nick'] user_id = user.id else: User.objects.create(username=str(res_dict['user_info']['nick']), password='') user = User.objects.filter(username=str(res_dict['user_info']['nick'])).first() dingding_id = res_dict['user_info']['nick'] user_id = user.id return redirect('http://localhost:8080/?dingding_id=' + str(dingding_id) + '&amp;' + 'uid=' + str(user_id)) #3.支付宝登陆 电脑网站支付文档： https://docs.open.alipay.com/270 快速接入：https://docs.open.alipay.com/270/105899/ 私钥：加密 公钥：解密 API列表：https://docs.open.alipay.com/270/105900/ 统一收单下单并支付页面接口：alipay.trade.page.pay 统一收单线下交易查询接口：alipay.trade.query 公共参数：sing_type,sing. 请求参数：和业务相关。out_trade_no:订单号。 线下查询：特殊可选参数，两个参数，添一个就行（订单号 或 支付宝号）。 SDK的使用：https://github.com/fzlee/alipay/blob/master/README.zh-hans.md 签名，使用SDK时，会自动处理签名 SDK: 安装：pip install python-alipay-sdk –upgrade 在支付宝中设置密码，公钥私钥 ​ Python ​ ​ 123456789101112131415161718192021222324252627282930313233343536373839404142from alipay import AliPay, DCAliPay, ISVAliPay # 导包app_private_key_string = open(os.path.join(路径)).read()alipay_public_key_string = open(os.path.join()).read()app_private_key_string == &quot;&quot;&quot; # 第三方包需要填写 在钥匙的上下写 -----BEGIN RSA PRIVATE KEY----- base64 encoded content -----END RSA PRIVATE KEY-----&quot;&quot;&quot;alipay_public_key_string == &quot;&quot;&quot; -----BEGIN PUBLIC KEY----- base64 encoded content -----END PUBLIC KEY-----&quot;&quot;&quot;alipay = AliPay( appid=&quot;&quot;, app_notify_url=None, # the default notify path app_private_key_string=app_private_key_string, # alipay public key, do not use your own public key! alipay_public_key_string=alipay_public_key_string, sign_type=&quot;RSA&quot;, # RSA or RSA2 debug=False # False by default.如果是沙箱环境。配置为True) # 如果你是Python 2用户（考虑考虑升级到Python 3吧），请确保非ascii的字符串为utf8编码： subject = u&quot;测试订单&quot;.encode(&quot;utf8&quot;) # 如果你是 Python 3的用户，使用默认的字符串即可 subject = &quot;测试订单&quot; # 电脑网站支付，需要跳转到https://openapi.alipay.com/gateway.do? + order_string order_string = alipay.api_alipay_trade_page_pay( out_trade_no=&quot;20161112&quot;, total_amount=0.01, subject=subject, return_url=&quot;https://example.com&quot;, notify_url=&quot;https://example.com/notify&quot; # 可选, 不填则使用默认notify url ) pay_url = &quot;https://openapi.alipay.com/gateway.do?&quot; + order_string 打开支付页面地址：window.open(pay_url) 统一收单线下交易查询：alipay.trade.query ​ Python ​ ​ 123# 支付接口app_private_key_string = open(os.path.join(settings.BASE_DIR,&quot;utils&quot;,&quot;key&quot;,&quot;app_private_key.txt&quot;)).read()alipay_public_key_string = open(os.path.join(settings.BASE_DIR,&quot;utils&quot;,&quot;key&quot;,&quot;alipay_public_key.txt&quot;)).read() app_private_key_string == &quot;&quot;&quot; -----BEGIN RSA PRIVATE KEY----- base64 encoded content -----END RSA PRIVATE KEY----- &quot;&quot;&quot; alipay_public_key_string == &quot;&quot;&quot; -----BEGIN PUBLIC KEY----- base64 encoded content -----END PUBLIC KEY----- &quot;&quot;&quot; alipay = AliPay( appid=&quot;2016101700704372&quot;, app_notify_url=&quot;http://127.0.0.1:8001/app/alipay_callback/&quot;, # 默认回调url app_private_key_string=app_private_key_string, # 支付宝的公钥，验证支付宝回传消息使用，不是你自己的公钥, alipay_public_key_string=alipay_public_key_string, sign_type=&quot;RSA2&quot;, # RSA 或者 RSA2 debug=False # 默认False ) class AlipayAPIView(APIView): def post(self, request): # 如果你是Python 2用户（考虑考虑升级到Python 3吧），请确保非ascii的字符串为utf8编码： # subject = u&quot;测试订单&quot;.encode(&quot;utf8&quot;) # 如果你是 Python 3的用户，使用默认的字符串即可 subject = &quot;XXX商家——护目镜&quot; # 电脑网站支付，需要跳转到https://openapi.alipay.com/gateway.do? + order_string order_string = alipay.api_alipay_trade_page_pay( out_trade_no=&quot;1906B00005&quot;, total_amount=9.01, subject=subject, return_url=&quot;http://127.0.0.1:8001/app/alipay_callback/&quot;, notify_url=&quot;http://127.0.0.1:8001/app/alipay_callback/&quot; # 可选, 不填则使用默认notify url ) # 支付页面的路由.返回给vue。 vue引导用户访问这个路由，进行支付 # windows.location.href=&quot;&quot; pay_url = &quot;https://openapi.alipaydev.com/gateway.do?&quot; + order_string print(pay_url) return Response({ &quot;code&quot;: 200, &quot;url&quot;: pay_url }) ```","link":"/posts/b9330e24/"},{"title":"vue基础语法","text":"vue是什么​ Vue是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应 用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当现代化的工具链与以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。 中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue安装由于vue项目依赖 node.js npm 需要先安装. 若没有请先安装; 1npm install -g vue-cli -g表示全局安装，vue-cli是模块，全局安装的模块可以在命令行直接使用 由于npm网站在国内速度非常慢，所以可以在命令后面加上淘宝的镜像 即： 1npm install -g vue-cli --registry=https://registry.npm.taobao.org 之后，可以vue –V查看vue是否安装好，出现版本号即安装成功。 创建项目1234567891.vue init webpack 项目名 //创建vue项目Project name —&gt; 项目名称 （非必填，默认上面的项目名） Project description —&gt; 项目描述 （非必填） Author —&gt; 作者（非必填）2.cd vue-test //进入项目目录3.npm install //安装依赖4.npm run dev //启动服务 vue基础语法v-html​ v-html 的特点可以执行和渲染html标签，它跟v-text 的区别就在此 1&lt;div v-html='msg'&gt;&lt;/div&gt; v-show​ 简单的判断 1&lt;h2 v-show='ok'&gt;阳光明媚&lt;/h2&gt; v-if、v-else-if、v-else12345&lt;div v-if=&quot;type === '狗'&quot;&gt;狗&lt;/div&gt;&lt;div v-else-if=&quot;type === '猫'&quot;&gt;B&lt;/div&gt;&lt;div v-else&gt; 既不是狗，也不是猫。&lt;/div&gt; v-for12345&lt;ul&gt; &lt;li v-for=&quot;(item,index) in tlist&quot;&gt; {{ item.test }} &lt;/li&gt;&lt;/ul&gt; 监听属性12345watch:{ counter:function(nval,oval){ console.log('计数器由'+oval+'变换为新的'+nval); } }, 计算属性1234567computed:{ // 反转 reverse_msg:function(){ console.log(this.msg.split('')); return this.msg.split('').reverse().join(''); }}, 购物车小案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;template&gt; &lt;div&gt; &lt;!-- 购物车 --&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;名称&lt;/td&gt; &lt;td&gt;数量&lt;/td&gt; &lt;td&gt;价格&lt;/td&gt; &lt;/tr&gt; &lt;tr v-for=&quot;(item,index) in tlist&quot;&gt; &lt;td&gt; {{ item.test }} &lt;/td&gt; &lt;td&gt; &lt;button @click=&quot;minus(index,1)&quot;&gt;-&lt;/button&gt; &lt;input type=&quot;text&quot; v-model='item.num'&gt; &lt;button @click=&quot;minus(index,0)&quot;&gt;+&lt;/button&gt; &lt;/td&gt; &lt;td&gt; {{ item.prict }} &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 总数量：{{ totalCount()[0] }} &lt;br/&gt; 总价格：{{ totalCount()[1] }}&lt;br/&gt;&lt;br/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default{ data(){ return{ tlist:[{test:'电脑',num:3,prict:9000},{test:'鼠标',num:3,prict:100},{test:'键 盘',num:3,prict:200},{test:'耳机',num:3,prict:90}], } }, // 自定义方法 methods:{ // 购物车总汇 totalCount:function(){ // 默认数量 let total = 0; let prict = 0; //遍历 for (let i=0,l=this.tlist.length;i&lt;l;i++){ // 汇总 total += this.tlist[i].num; prict += (this.tlist[i].num * this.tlist[i].prict); } return [total,prict] }, minus:function(index,on){ if (on){ if (this.tlist[index].num&gt;0){ this.tlist[index].num--; } } else{ this.tlist[index].num++; } }, }&lt;/script&gt; 执行效果：","link":"/posts/468ef951/"},{"title":"Django如何配置并实现简单注册功能","text":"Django是什么？Django是一个开放源代码的Web应用框架，由Python写成。采用了MVT的软件设计模式，即模型，视图和模板。它在开发初期用于管理劳伦斯出版集团旗下的一些以新闻为主的网站。Django于2005年7月在BSD许可证下发布，它的名字来源于比利时的吉普赛爵士吉他手Django Reinhardt。 为什么选择Django使用Django，可以在几小时内将Web应用程序从概念带到启动。Django处理了许多Web开发的麻烦，因此可以专注于编写应用程序而无需重新发明轮子。并且它是免费和开源的。简单来说就是它速度快、可扩展性强。 Django安装12pip install django #安装最新Djangopip install django==2.0.4 #指定版本安装 验证版本： 1pip list Django创建项目1234567891011生成django项目django-admin startproject 项目名生成django子应用python manage.py startapp 项目名启动django服务python manage.py runserver settings.py配置文件的修改12345678910111213141516171819202122232425262728293031更改配置文件1.找到应用的settings.py2.注释MIDDLEWARE中的csr注册子应用INSTALLED_APPS=[子应用名]修改数据库名：name= 数据库名更改语言LANGUAGE = 'zh-Hans'更改时区TIME_ZOHE = 'Asia/Shanghai'USE_TZ = False添加静态文件夹： 在配置文件最后STATICFILES_DIRS = [so.path.join(BASE_DIR,'static')] 迁移以及迁移失败的解决方法生成迁移文件 1python manage.py makemigrations 执行迁移 1python manage.py migrate 若执行迁移不成功，就删除migrations文件夹和对应数据库的所有表，重新执行上面的两条命令。 若还不成功就在数据库手动建表，反向迁移 1python manage.py inspectdb &gt; 应用名称/models.py Django 注册小案例##注册逻辑： 12345678910111213141516171819202122# 注册接口class Register(APIView): def get(self,request): # 接收参数 username = request.GET.get('username',None) password = request.GET.get('password',None) # 排重操作 user = User.objects.filter(username=username).first() if user: return Response({'code':403,'message':'该用户名已存在'}) # 入库 user = User(username = username,password = make_password(password)) # 保存结果 user.save() return Response({'code':200,'message':'恭喜注册成功'})","link":"/posts/79e097c4/"},{"title":"Docker常用命令","text":"Docker常用命令一、常用命令 docker version docker info docker help 二、镜像命令1. docker images 功能： 列出本地主机上的镜像 各个选项说明: 12345REPOSITORY：表示镜像的仓库源TAG：镜像的标签IMAGE ID：镜像IDCREATED：镜像创建时间SIZE：镜像大小 同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。 如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像 OPTIONS说明： -a :列出本地所有的镜像（含中间映像层） -q :只显示镜像ID。 –digests :显示镜像的摘要信息 –no-trunc :显示完整的镜像信息 2. docker search 某个XXX镜像名字 镜像仓库：https://hub.docker.com 命令： docker search [OPTIONS] 镜像名字 OPTIONS说明： –no-trunc : 显示完整的镜像描述 -s : 列出收藏数不小于指定值的镜像。 –automated : 只列出 automated build类型的镜像； 3. docker pull 某个XXX镜像名字 功能: 下载镜像 docker pull 镜像名字[:TAG] 4.docker rmi 某个XXX镜像名字ID 功能：删除镜像 删除单个： docker rmi -f 镜像ID 删除多个： docker rmi -f 镜像名1:TAG 镜像名2:TAG 删除全部： docker rmi -f $(docker images -qa) 作业：结合我们Git的学习心得，大家猜猜是否会有 docker commit /docker push？？ 三、容器命令 有镜像才能创建容器，这是根本前提(下载一个CentOS镜像演示)docker pull centos 1. 新建并启动容器 docker run [OPTIONS] IMAGE [COMMAND] [ARG…] OPTIONS说明（常用）：有些是一个减号，有些是两个减号 12345678910--name=&quot;容器新名字&quot;: 为容器指定一个名称；-d: 后台运行容器，并返回容器ID，也即启动守护式容器；-i：以交互模式运行容器，通常与 -t 同时使用；-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；-P: 随机端口映射；-p: 指定端口映射，有以下四种格式 ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort 启动交互式容器 12#使用镜像centos:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。docker run -it centos /bin/bash 2. 列出当前所有正在运行的容器 docker ps [OPTIONS] OPTIONS说明（常用）： 12345-a :列出当前所有正在运行的容器+历史上运行过的-l :显示最近创建的容器。-n：显示最近n个创建的容器。-q :静默模式，只显示容器编号。--no-trunc :不截断输出。 3. 退出容器(两种退出方式) 容器停止退出 exit 容器不停止退出 ctrl+P+Q 4. 启动容器 docker start 容器ID或者容器名 5. 重启容器 docker restart 容器ID或者容器名 6. 停止容器 docker stop 容器ID或者容器名 7. 强制停止容器 docker kill 容器ID或者容器名 8. 删除已停止的容器 docker rm 容器ID 一次性删除多个容器 docker rm -f $(docker ps -a -q) docker ps -a -q | xargs docker rm 9. 重点 启动守护式容器 docker run -d 容器名 123456789101112#使用镜像centos:latest以后台模式启动一个容器docker run -d centos 问题：然后docker ps -a 进行查看, 会发现容器已经退出很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程.容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。 这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下,我们配置启动服务只需要启动响应的service即可。例如service nginx start但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用,这样的容器后台启动后,会立即自杀因为他觉得他没事可做了.所以，最佳的解决方案是,将你要运行的程序以前台进程的形式运行 查看容器日志 docker logs -f -t –tail 容器ID docker run -d centos /bin/sh -c “while true;do echo hello ljj;sleep 2;done” -t 是加入时间戳 -f 跟随最新的日志打印 –tail 数字 显示最后多少条 –tail 数字 显示最后多少条 查看容器内运行的进程 docker top 容器ID 查看容器内部细节 docker inspect 容器ID 进入正在运行的容器并以命令行交互 docker exec -it 容器ID bashShell ​ 1`docker exec -it 81bb90b25582 /bin/bash` 重新进入: docker attach 容器ID 上述两个区别: attach: 直接进入容器启动命令的终端，不会启动新的进程 exec: 是在容器中打开新的终端，并且可以启动新的进程 再次查看容器的进程：docker top 81bb90b25582 从容器内拷贝文件到主机上 docker cp 容器ID:容器内路径 目的主机路径 docker cp 81bb90b25582:/tmp/a.txt /tmp/aa.txt 四、总结 12345678910111213141516171819202122232425262728293031323334353637attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像commit Create a new image from a container changes # 提交当前容器为新的镜像cp Copy files/folders from the containers filesystem to the host path #从容器中拷贝指定文件或者目录到宿主机中create Create a new container # 创建一个新的容器，同 run，但不启动容器diff Inspect changes on a container's filesystem # 查看 docker 容器变化events Get real time events from the server # 从 docker 服务获取容器实时事件exec Run a command in an existing container # 在已存在的容器上运行命令export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ]history Show the history of an image # 展示一个镜像形成历史images List images # 列出系统当前镜像import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应export]info Display system-wide information # 显示系统相关信息inspect Return low-level information on a container # 查看容器详细信息kill Kill a running container # kill 指定 docker 容器load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save]login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器logout Log out from a Docker registry server # 从当前 Docker registry 退出logs Fetch the logs of a container # 输出当前容器日志信息port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口pause Pause all processes within a container # 暂停容器ps List containers # 列出容器列表pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器restart Restart a running container # 重启运行的容器rm Remove one or more containers # 移除一个或者多个容器rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除]run Run a command in a new container # 创建一个新的容器并运行一个命令save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load]search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像start Start a stopped containers # 启动容器stop Stop a running containers # 停止容器tag Tag an image into a repository # 给源中镜像打标签top Lookup the running processes of a container # 查看容器中运行的进程信息unpause Unpause a paused container # 取消暂停容器version Show the docker version information # 查看 docker 版本号wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值","link":"/posts/29dc6fe8/"},{"title":"最新win10专业版密钥激活","text":"最新win10专业版密钥激活win10专业版密钥激活 1、查看激活状态，win按键》设置（左下角倒数第二个）》更新和安全》激活———提示没有有效密钥，需要激活 2、管理员身份打开cmd，搜索框输入cmd，以管理员身份运行 3、卸载产品密钥：执行命令— slmgr.vbs /upk 并弹出窗口显为“已成功卸载了产品密钥”； 4、安装产品密钥：执行命令— *slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX *并弹出窗口提示：“成功的安装了产品密钥”； 5、修改指定名称：执行命令— *slmgr /skms zh.us.to *并弹出窗口提示：“密钥管理服务计算机名成功的设置为zh.us.to”； 6、激活所需产品：执行命令— *slmgr /ato *并弹出窗口提示：“成功的激活了产品”","link":"/posts/915b7b32/"}],"tags":[{"name":"加密文章","slug":"加密文章","link":"/tags/%E5%8A%A0%E5%AF%86%E6%96%87%E7%AB%A0/"},{"name":"python基础","slug":"python基础","link":"/tags/python%E5%9F%BA%E7%A1%80/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"vue","slug":"vue","link":"/tags/vue/"},{"name":"七牛云","slug":"七牛云","link":"/tags/%E4%B8%83%E7%89%9B%E4%BA%91/"},{"name":"django","slug":"django","link":"/tags/django/"},{"name":"三方登录","slug":"三方登录","link":"/tags/%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/"},{"name":"vue基础","slug":"vue基础","link":"/tags/vue%E5%9F%BA%E7%A1%80/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"日记","slug":"日记","link":"/tags/%E6%97%A5%E8%AE%B0/"},{"name":"windows10专业版","slug":"windows10专业版","link":"/tags/windows10%E4%B8%93%E4%B8%9A%E7%89%88/"},{"name":"docker命令","slug":"docker命令","link":"/tags/docker%E5%91%BD%E4%BB%A4/"}],"categories":[{"name":"private","slug":"private","link":"/categories/private/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"vue","slug":"python/vue","link":"/categories/python/vue/"},{"name":"三方登录","slug":"三方登录","link":"/categories/%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/"},{"name":"七牛云","slug":"python/vue/七牛云","link":"/categories/python/vue/%E4%B8%83%E7%89%9B%E4%BA%91/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"爬虫","slug":"爬虫","link":"/categories/%E7%88%AC%E8%99%AB/"},{"name":"vue","slug":"vue","link":"/categories/vue/"},{"name":"日记","slug":"日记","link":"/categories/%E6%97%A5%E8%AE%B0/"},{"name":"django","slug":"django","link":"/categories/django/"},{"name":"Windows激活教程","slug":"Windows激活教程","link":"/categories/Windows%E6%BF%80%E6%B4%BB%E6%95%99%E7%A8%8B/"},{"name":"docker命令","slug":"docker命令","link":"/categories/docker%E5%91%BD%E4%BB%A4/"}]}